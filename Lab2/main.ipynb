{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "18931aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/receptor/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/receptor/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Generator, Dict, List\n",
    "from unicodedata import category\n",
    "\n",
    "import contractions\n",
    "import nltk as nlp\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nlp.download('stopwords')\n",
    "nlp.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1d18d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROOT = Path(__file__).parent.resolve()\n",
    "# DATA = ROOT / 'war_and_peace_full.txt'\n",
    "DATA = Path('war_and_peace_full.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "12570ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_text(text: str, punctuation: str) -> str:\n",
    "    t = contractions.fix(text)\n",
    "    t = t.lower()\n",
    "    t = t.translate(str.maketrans('', '', punctuation))\n",
    "    t = ' '.join([word for word in t.split() if not any(letter.isdigit() for letter in word)])\n",
    "#     t = ' '.join([word for word in t.split() if word not in stopwords.words('english')])\n",
    "    t = ' '.join(list(filter(lambda x: len(x) > 1, [WordNetLemmatizer().lemmatize(word) for word in t.split()])))\n",
    "    t = t.strip()\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2738b005",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrs = (chr(i) for i in range(sys.maxunicode + 1))\n",
    "punctuation = set(c for c in chrs if category(c).startswith(\"P\")) | set(string.punctuation)\n",
    "punctuation = ''.join(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "513880fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'⹍【‰𑩅⁏𑗖᰽❲𐫴〔𑇍︽：⸼၌﹁𐄂﹇[᭞﹝⁋𑪞₎⟨𐕯𑇇𑙥︒׳»܌꛷𑪡᨞〕︓᯿༇𖭄#︑𑗎᐀︻𐩘›᜵፤｠⸥＼꧟⹊׀︾༌๏꧅؞᪪𑿿։፥″᥄𑪛꘍꙳᳁‿𑗄﹜᰻–❭⦑༐︰『𑗏꛵࡞‑⸋﹄𑩁「﹏꣺⸤꡵𑑛⁓፣＊⁇᪦𑁉⁁꧄‶﹚។⸅⹁𐫳܂〙।܅｡𑈸𐽘⹇𑙃࠰{꫱፡&］࠴৽）࠾︲｛܀⸒᳀⦇꘎‴†𑙬︔𑈼⁃⹅;᭚𐽖་⳼⸲៘—᥅𐩑︴︐𖩮྅꧆﹆﹔〖𑙠࿒⦉⁉᪠𑑏⸴𑇟𑗔⸬𐮛።𑙦＿𑙂࠶⸕⟯❯⸶〝𐫲︸⸇︗𒑳❱՜｟⸍︘︿٭᭜꓿𐏐⸳𑙡𖬸𑙪⸠𖬹⦔𑂼၏𐩔⸻𑱃＇꓾⸀᜶؍〉¿࠼𖬻⌉಄．’〽꡴𐮜⸝𑱰༅𐫶‘᭠︙％⦆‟𝪉<𐫰‥𐽗𖺚𑩄⹉꡷꛳᳓﹍𐤟⧛﹋꛶⸫⸩𑑝𑗌⦅＠𑑋՛࿔᪤෴᭛⟅꧇፦꧉૰፠⸹᳂𖩯𑪜‵᛬𐩐𝪊༑:༻᯽⹆፨𒑰;᠂།‚，𑃀࠸؉࿐⸱༏=‽⁙𑧢𑅀𐫵.꡶𑪟𑗃⟪⸰…﹑؟༈（𐬼᪬؊⸦𑅂౷꘏᚜❪꙾᰼-⁅𞥞᪩𑅁﹐`”⸗⸽࿚၊״︖𑇆༼᛫꤯꫞❰〈〃⸔𑗒᳃༎༉࿓⟭᠈⸛@𐩒𐎟꤮꩜⹄⹎⸢》𑗕𑇈𑩀𖬺⸌𒑴𑗑࿑᪨⁞?；᪫﹎⁑⹈⸸᱿⦕⸊／⟩⵰𑜼❳⸂᳄⁊᰿𑗈𑗁⦓⸆꩟+၍„!𖬷⟮⟦⸏༊(⸎〗」⸚꛴＆︹‷｣՚𑁇׃܃߸꧃﹉𑑍﹛𑁈﹒߷꣸࠵⸡𑱱〘⟫﹣―《𑗐′꣹︶𖺘༺𑗅᙮‗᰾⦘᪥‐﹗﹨⦎𑩂。๚⁂𑁍﹖,⁍⦈⁛𑙨᪡₍꣼॰⸙⸿𑇛𑗓〚⳿𖺗𐩿⌋࠷‸࠱𑈽⸄⟆＃⁔﹈᠄⸜᠊⸷⁾¡؛“⁚𑪢‹𝪈܆⁜﹌§᪣᛭𐄁՝⹏\\'࠻჻⹂꩝』𐮚、>࠽꛲⁝\\\\܁𑠻⸾॥꯫𑈹︷⁎𝪇！𑙧⦄⸁𑅴𐤿﹂᱾՞᳆‧𐩗𑪠៖⁘⳾꧞＂𑱂𑃁𑨿៕࠹⧚❨༔՟*⸟⹋゠\"¶۔꧈⦒‱༄⸐𐡗⁈𑈻៙༒᭟⁆｢𑻷꧍⸵𑱁־𒑲꧊𖺙٫။⸉⟧﴾⸘𝪋‖‡⦖𑙫⧙〞}𑩆𑗍๛⸨꧂𑂾𑻸𐽙⦍－⸖︼꣏꧌𑗊𑩃⦋𑇅𑙤⧽꥟⸧𑅵❫❵〜𑂻﹟꣎⸈᠃⦊𖿢᯾⁀$/࠺⸪܈︕᪭꩞﹞𑂿⌊𐬿%𑑌⁌𑗉~﹙⹃𑗗᠆᠇⸞⧼𐬺᨟꫟꧁܇､᭝𐬽｝・𖫵၎﹫𑗇᠅﹘𑙁·︵〉⸺⸣៚᠁𐽕٬‣𐫱𞥟𑗋٪❩܉․࠲﹕࠳᠉࿙༆［^𑊩܋•𐬹𒑱】⦏〟𑓆᯼𑅃⸭𑙣⁕⦗𑪚︳﹀𑇝𑑎⧘⁖𐩓𑁋﴿‒𑱅܊᪢᚛⹌꧋﹪܍❬﹡𐮙⸃⳹੶)‼𑗆𛲟﹊⦐𑜾﹃･⳺𑇞_𑁌᠀︺𑱄𐄀׆𐬻᳅،❮𐩖⳻꫰⁗༽|⟬«﹠⁽？܄⁐⦌‾𑜽֊⌈⸑⸮𑈺፧𑗂⹀𑙩߹〛〰⦃︱〈𑙢𐩕❴𑁊𐬾‛⸓]﹅᳇·※'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e746ec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_generator(file_name: str, key: str) -> Generator[List[str], None, None]:\n",
    "    with open(file_name) as f_read:\n",
    "        content = []\n",
    "\n",
    "        for line in f_read:\n",
    "            if line.startswith(key):\n",
    "                yield content\n",
    "                content = []\n",
    "            else:\n",
    "                content.append(line)\n",
    "        if content:\n",
    "            yield content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b7254c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequency_ngram(text: str, n_gram: int = 2) -> Dict[str, int]:\n",
    "    counts = {}\n",
    "    \n",
    "    for word in text.split(' '):\n",
    "        for i in range(0, len(word)):\n",
    "            chunk = word[i:i + n_gram]\n",
    "\n",
    "            if len(chunk) == n_gram:\n",
    "                counts[chunk] = counts.get(chunk, 0) + 1\n",
    "                \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f7b62b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dict(d1: dict, d2: dict) -> Dict[str, int]:\n",
    "    for k in d2.keys():\n",
    "        d1[k] = d1.get(k, 0) + d2[k]\n",
    "    return d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bae8019e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOOK1\n",
      "Chapters: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 \n",
      "\n",
      "BOOK2\n",
      "Chapters: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 \n",
      "\n",
      "BOOK3\n",
      "Chapters: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "\n",
      "BOOK4\n",
      "Chapters: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \n",
      "\n",
      "BOOK5\n",
      "Chapters: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 \n",
      "\n",
      "BOOK6\n",
      "Chapters: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 \n",
      "\n",
      "BOOK7\n",
      "Chapters: 1 2 3 4 5 6 7 8 9 10 11 12 13 \n",
      "\n",
      "BOOK8\n",
      "Chapters: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 \n",
      "\n",
      "BOOK9\n",
      "Chapters: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 \n",
      "\n",
      "BOOK10\n",
      "Chapters: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 \n",
      "\n",
      "BOOK11\n",
      "Chapters: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 \n",
      "\n",
      "BOOK12\n",
      "Chapters: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \n",
      "\n",
      "BOOK13\n",
      "Chapters: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "\n",
      "BOOK14\n",
      "Chapters: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \n",
      "\n",
      "BOOK15\n",
      "Chapters: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "frequencies = dict()\n",
    "\n",
    "for idx_book, book in enumerate(txt_generator(DATA.as_posix(), 'BOOK')):\n",
    "    if not ''.join(book).strip():\n",
    "        continue\n",
    "    \n",
    "    file_book = Path('book.txt')\n",
    "\n",
    "    with open(file_book.as_posix(), 'w') as f:\n",
    "        f.writelines(book)\n",
    "    \n",
    "    print(f'BOOK{idx_book}\\nChapters:', end=' ')\n",
    "    for idx_chapter, chapter in enumerate(txt_generator(file_book.as_posix(), 'CHAPTER')):\n",
    "        if not ''.join(chapter).strip():\n",
    "            continue\n",
    "\n",
    "        print(idx_chapter, end=' ')\n",
    "        \n",
    "        text_chapter = ' '.join(chapter)\n",
    "        text_chapter: str = processing_text(text_chapter, punctuation)\n",
    "        \n",
    "        counts: dict = get_frequency_ngram(text_chapter, n_gram=2)\n",
    "        frequencies: dict = update_dict(frequencies, counts)\n",
    "\n",
    "    print('\\n')\n",
    "\n",
    "frequencies = {k: v for k, v in sorted(frequencies.items(), reverse=True, key=lambda item: item[1])}\n",
    "\n",
    "with open('frequencies.json', 'w') as file:\n",
    "    json.dump(frequencies, file, indent=4, sort_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4da37979",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'he': 74710, 'th': 73814, 'in': 48123, 'an': 45826, 'er': 43326, 're': 35413, 'nd': 34569, 'ed': 28607, 'at': 27994, 'ha': 26863, 'on': 26108, 'hi': 25815, 'en': 25625, 'ng': 24971, 'to': 23716, 'ou': 23672, 'is': 22202, 'it': 21137, 'or': 19736, 'te': 18393, 'st': 17843, 'ar': 17801, 'se': 17311, 'of': 16988, 'le': 16772, 'nt': 16026, 'ne': 14819, 'ro': 14723, 'me': 14682, 've': 14378, 'al': 14228, 'de': 13755, 'no': 13748, 'ti': 13699, 'ho': 13680, 'ea': 13391, 'll': 13376, 'ce': 13129, 'es': 13092, 'ri': 12880, 'co': 12832, 'wa': 12170, 'wh': 11926, 'be': 11494, 'ot': 11310, 'ad': 11273, 'om': 11060, 'ut': 10949, 'ch': 10875, 'sh': 10859, 'wi': 10563, 'el': 10156, 'ly': 10093, 'ow': 9914, 'im': 9814, 'ma': 9688, 'ss': 9443, 'li': 9316, 'nc': 9108, 'si': 9086, 'un': 8762, 'ai': 8726, 'id': 8645, 'so': 8558, 'ic': 8506, 'il': 8461, 'sa': 8432, 'us': 8372, 'lo': 8297, 'fo': 8203, 'pe': 8184, 'ra': 8083, 'ur': 7987, 'ee': 7861, 'pr': 7858, 'we': 7756, 'di': 7688, 'as': 7671, 'ie': 7660, 'ta': 7608, 'la': 7597, 'ol': 7357, 'et': 7356, 'oo': 7298, 'io': 7271, 'em': 7117, 'ld': 7038, 'ac': 7012, 'os': 6733, 'ca': 6721, 'mo': 6644, 'ul': 6389, 'yo': 6006, 'gh': 5968, 'ry': 5943, 'ir': 5910, 'ge': 5836, 'ov': 5731, 'ni': 5685, 'fr': 5671, 'tr': 5670, 'ke': 5662, 'ec': 5584, 'na': 5532, 'ev': 5293, 'bu': 5275, 'ay': 5204, 'do': 4950, 'rr': 4933, 'rs': 4774, 'mi': 4763, 'po': 4742, 'am': 4707, 'fi': 4665, 'rt': 4631, 'wo': 4566, 'fe': 4519, 'vi': 4508, 'tt': 4414, 'pa': 4409, 'av': 4375, 'rd': 4370, 'ig': 4299, 'pl': 4220, 'ht': 4207, 'pi': 4188, 'ct': 4135, 'bo': 4053, 'su': 3947, 'ns': 3903, 'ap': 3902, 'fa': 3878, 'if': 3793, 'ey': 3725, 'bl': 3627, 'ei': 3497, 'dr': 3474, 'ab': 3460, 'ep': 3438, 'mp': 3435, 'ki': 3388, 'ag': 3379, 'ga': 3374, 'ty': 3352, 'ok': 3337, 'iv': 3307, 'ug': 3250, 'sp': 3241, 'ew': 3224, 'ef': 3200, 'ba': 3188, 'ex': 3134, 'go': 3100, 'op': 3062, 'od': 3054, 'tl': 3006, 'tu': 2966, 'rm': 2936, 'ia': 2911, 'ru': 2896, 'ff': 2839, 'up': 2775, 'gr': 2743, 'pp': 2625, 'ck': 2625, 'ye': 2574, 'rn': 2568, 'by': 2556, 'ci': 2550, 'ak': 2533, 'my': 2522, 'au': 2510, 'gi': 2492, 'da': 2481, 'lf': 2330, 'qu': 2329, 'oi': 2235, 'sc': 2234, 'wn': 2224, 'aw': 2164, 'nl': 2161, 'sk': 2157, 'ft': 2152, 'nn': 2149, 'eg': 2149, 'ny': 2102, 'kn': 2071, 'cr': 2071, 'uc': 2048, 'cl': 2005, 'br': 1978, 'ue': 1892, 'fu': 1861, 'ui': 1757, 'sm': 1695, 'va': 1693, 'cu': 1690, 'af': 1689, 'lt': 1658, 'mu': 1645, 'eo': 1642, 'hu': 1593, 'nk': 1491, 'lu': 1477, 'gl': 1476, 'rc': 1475, 'vo': 1463, 'pt': 1447, 'ms': 1439, 'ud': 1411, 'rg': 1399, 'oc': 1394, 'oa': 1392, 'mm': 1383, 'um': 1368, 'xp': 1355, 'ás': 1354, 'gu': 1335, 'ua': 1322, 'dy': 1310, 'tá': 1310, 'dd': 1304, 'hr': 1276, 'rl': 1272, 'ib': 1272, 'dl': 1260, 'sl': 1216, 'fl': 1210, 'ik': 1198, 'ya': 1194, 'ju': 1183, 'tw': 1181, 'óv': 1159, 'pu': 1158, 'du': 1112, 'mb': 1088, 'yi': 1069, 'lk': 1056, 'cc': 1050, 'tó': 1026, 'bi': 1002, 'nu': 967, 'gn': 933, 'rk': 928, 'ón': 928, 'nf': 915, 'ys': 914, 'hy': 904, 'ub': 897, 'ob': 891, 'yt': 851, 'ip': 844, 'ts': 830, 'kh': 827, 'ís': 771, 'og': 769, 'nv': 753, 'eh': 737, 'ze': 729, 'jo': 716, 'sw': 713, 'oy': 702, 'rv': 694, 'ls': 685, 'ku': 666, 'tc': 655, 'tú': 654, 'zo': 631, 'vs': 614, 'xc': 604, 'iz': 576, 'je': 563, 'rp': 547, 'úz': 538, 'vn': 533, 'wr': 529, 'ní': 518, 'ka': 513, 'lw': 479, 'ds': 471, 'xt': 471, 'lr': 470, 'rf': 464, 'só': 454, 'oe': 447, 'gg': 447, 'sb': 442, 'dg': 435, 'ph': 418, 'lv': 408, 'bs': 399, 'lm': 396, 'ól': 394, 'lp': 388, 'sy': 386, 'hm': 379, 'wd': 368, 'oh': 365, 'íl': 355, 'py': 350, 'sn': 348, 'az': 348, 'dó': 344, 'kó': 342, 'kl': 340, 'xa': 337, 'rí': 334, 'cy': 333, 'pá': 330, 'uf': 330, 'ah': 325, 'ps': 323, 'dv': 321, 'rá': 319, 'ít': 318, 'dm': 317, 'tm': 315, 'eu': 315, 'sf': 313, 'rw': 305, 'ét': 298, 'xi': 289, 'án': 284, 'há': 282, 'ár': 280, 'sí': 278, 'ek': 278, 'pé': 278, 'ín': 273, 'eb': 272, 'ix': 258, 'bt': 257, 'eq': 255, 'ko': 255, 'ws': 252, 'xe': 252, 'nq': 243, 'mí': 243, 'hé': 242, 'zi': 241, 'dn': 238, 'áv': 237, 'dj': 236, 'gt': 235, 'mn': 234, 'bb': 229, 'rh': 228, 'rb': 220, 'lè': 219, 'áy': 218, 'vl': 216, 'yl': 208, 'wl': 201, 'tf': 189, 'él': 183, 'át': 178, 'bj': 175, 'má': 173, 'tn': 172, 'yc': 172, 'ez': 170, 'sq': 169, 'aj': 168, 'èn': 167, 'ym': 166, 'gs': 166, 'yá': 166, 'hí': 165, 'ml': 163, 'ió': 162, 'én': 160, 'vá': 158, 'nb': 157, 'yb': 157, 'yf': 157, 'nh': 155, 'úk': 155, 'zh': 154, 'hl': 153, 'uo': 149, 'ví': 147, 'nm': 145, 'ág': 142, 'ox': 141, 'ús': 140, 'mf': 138, 'tz': 137, 'ée': 137, 'nw': 134, 'ëv': 134, 'iu': 130, 'pc': 127, 'rú': 126, 'lé': 125, 'hë': 125, 'ln': 123, 'nj': 120, 'oj': 119, 'hn': 118, 'nó': 118, 'cq': 117, 'oz': 117, 'df': 116, 'ks': 109, 'ík': 109, 'vy': 107, 'np': 105, 'zú': 105, 'tí': 102, 'ér': 101, 'gy': 101, 'ky': 100, 'pf': 100, 'za': 99, 'yw': 98, 'ja': 98, 'lá': 97, 'kr': 97, 'uk': 96, 'hk': 96, 'lí': 95, 'lg': 93, 'yr': 93, 'kw': 89, 'vé': 87, 'vr': 87, 'sd': 86, 'ré': 86, 'fy': 85, 'ej': 85, 'mr': 83, 'nx': 82, 'lb': 82, 'rz': 82, 'uv': 81, 'dh': 80, 'db': 80, 'nr': 79, 'mó': 79, 'sv': 79, 'mt': 77, 'áe': 76, 'lc': 75, 'ró': 75, 'uz': 74, 'dt': 73, 'hf': 70, 'ká': 70, 'hb': 69, 'dk': 69, 'bm': 69, 'íb': 68, 'ae': 67, 'hc': 65, 'zm': 64, 'wk': 63, 'dw': 63, 'hd': 63, 'ló': 61, 'xh': 60, 'fs': 58, 'ád': 56, 'ór': 55, 'yp': 55, 'gd': 55, 'cs': 54, 'yn': 53, 'gé': 53, 'yu': 53, 'èc': 52, 'ax': 51, 'wf': 50, 'kc': 50, 'sg': 49, 'hs': 48, 'éy': 48, 'zz': 47, 'bv': 46, 'dq': 46, 'fc': 45, 'zl': 44, 'xé': 44, 'rë': 44, 'óy': 43, 'ao': 42, 'hw': 42, 'uh': 42, 'év': 42, 'ux': 41, 'wy': 41, 'ók': 41, 'ën': 40, 'yí': 40, 'tp': 39, 'ák': 38, 'zá': 38, 'lú': 38, 'mc': 37, 'tb': 37, 'aï': 37, 'ïv': 37, 'yk': 37, 'áz': 37, 'úr': 36, 'ém': 35, 'bé': 35, 'út': 34, 'hö': 33, 'fw': 32, 'më': 32, 'vó': 32, 'gá': 32, 'èr': 30, 'yh': 30, 'ww': 30, 'km': 30, 'fb': 29, 'sr': 29, 'mé': 29, 'úg': 28, 'pm': 27, 'iq': 27, 'zd': 27, 'gw': 26, 'zu': 26, 'ám': 26, 'mü': 26, 'oq': 25, 'lz': 25, 'dá': 25, 'gó': 25, 'ím': 23, 'wt': 23, 'nz': 22, 'té': 22, 'wc': 22, 'ön': 22, 'üt': 22, 'aé': 22, 'fé': 21, 'uy': 21, 'ël': 21, 'wu': 20, 'vu': 20, 'pw': 20, 'bw': 20, 'pó': 20, 'fë': 19, 'ëd': 19, 'gm': 19, 'êt': 19, 'sá': 19, 'pk': 18, 'íc': 18, 'rü': 18, 'aa': 18, 'tv': 18, 'ýs': 18, 'xu': 17, 'kf': 17, 'mh': 17, 'ün': 17, 'zn': 17, 'bá': 17, 'íz': 17, 'ëz': 17, 'bd': 16, 'kg': 16, 'ii': 16, 'kí': 16, 'sé': 15, 'mw': 15, 'lh': 15, 'dé': 15, 'dí': 15, 'bí': 15, 'zy': 14, 'ná': 14, 'rè': 14, 'rq': 14, 'tg': 13, 'ál': 13, 'éc': 13, 'öw': 13, 'hh': 13, 'kv': 13, 'úl': 13, 'bn': 12, 'és': 12, 'kb': 12, 'xv': 12, 'bó': 12, 'yg': 12, 'pb': 12, 'ég': 12, 'dc': 12, 'yd': 11, 'hè': 11, 'yy': 11, 'ji': 11, 'ür': 11, 'fp': 11, 'tk': 11, 'úe': 11, 'éd': 10, 'tê': 10, 'kú': 10, 'hó': 10, 'yz': 10, 'wb': 10, 'gf': 10, 'rý': 10, 'wg': 10, 'vd': 10, 'cd': 9, 'hp': 9, 'fk': 9, 'cw': 9, 'ír': 9, 'fh': 9, 'mè': 9, 'dp': 9, 'pn': 9, 'vk': 9, 'wü': 9, 'úb': 8, 'kt': 8, 'áp': 8, 'sú': 8, 'ný': 8, 'ói': 8, 'vw': 7, 'ih': 7, 'iw': 7, 'hú': 7, 'yú': 7, 'fd': 7, 'cé': 7, 'né': 7, 'úc': 7, 'ès': 6, 'të': 6, 'ëm': 6, 'mk': 6, 'sz': 6, 'éo': 6, 'lý': 6, 'vt': 6, 'gc': 6, 'ób': 6, 'xy': 6, 'fn': 6, 'aë': 6, 'gz': 6, 'ýn': 5, 'là': 5, 'ké': 5, 'wm': 5, 'íd': 5, 'lë': 5, 'cz': 5, 'üh': 5, 'hv': 5, 'ós': 5, 'xo': 5, 'ód': 5, 'èd': 5, 'aú': 5, 'ék': 5, 'eà': 4, 'àt': 4, 'md': 4, 'bc': 4, 'ót': 4, 'xq': 4, 'mê': 4, 'xl': 4, 'pè': 4, 'ça': 4, 'zé': 4, 'éw': 4, 'sj': 4, 'iè': 4, 'tä': 4, 'äd': 4, 'zk': 4, 'ýp': 4, 'td': 4, 'gp': 4, 'èv': 4, 'bú': 4, 'áf': 4, 'xs': 4, 'aî': 3, 'ît': 3, 'tj': 3, 'ât': 3, 'rj': 3, 'zv': 3, 'ué': 3, 'dý': 3, 'cm': 3, 'hg': 3, 'zí': 3, 'dü': 3, 'âc': 3, 'óm': 3, 'nç': 3, 'vg': 3, 'fm': 3, 'fó': 3, 'hâ': 3, 'âl': 3, 'ës': 3, 'kp': 3, 'gí': 3, 'âm': 3, 'pú': 3, 'áw': 3, 'vý': 3, 'ýd': 3, 'fí': 3, 'óz': 3, 'cœ': 3, 'œy': 3, 'kd': 3, 'ôt': 2, 'bâ': 2, 'êl': 2, 'dz': 2, 'dè': 2, 'oï': 2, 'ïs': 2, 'ié': 2, 'rç': 2, 'ço': 2, 'râ': 2, 'êm': 2, 'gú': 2, 'óg': 2, 'óf': 2, 'në': 2, 'uw': 2, 'aq': 2, 'úp': 2, 'wp': 2, 'ív': 2, 'sè': 2, 'xm': 2, 'úd': 2, 'gk': 2, 'lq': 2, 'oú': 2, 'bh': 2, 'bê': 2, 'éz': 2, 'zs': 2, 'dâ': 2, 'dê': 2, 'eý': 2, 'ýk': 2, 'vú': 2, 'uu': 2, 'rô': 2, 'ôl': 2, 'pg': 2, 'hô': 1, 'çe': 1, 'yé': 1, 'rê': 1, 'fg': 1, 'óo': 1, 'nú': 1, 'úf': 1, 'wú': 1, 'rä': 1, 'äu': 1, 'kü': 1, 'üm': 1, 'wó': 1, 'nô': 1, 'ép': 1, 'zó': 1, 'wí': 1, 'tü': 1, 'üc': 1, 'vb': 1, 'qc': 1, 'cè': 1, 'aç': 1, 'èg': 1, 'eú': 1, 'éi': 1, 'éb': 1, 'yv': 1, 'áb': 1, 'éa': 1, 'dë': 1, 'èt': 1, 'gq': 1, 'uq': 1, 'vv': 1, 'kö': 1, 'iy': 1, 'kk': 1, 'mú': 1, 'aí': 1, 'zc': 1, 'ác': 1, 'éx': 1, 'óa': 1, 'zw': 1, 'wä': 1, 'äc': 1, 'éâ': 1, 'fâ': 1, 'xf': 1, 'íp': 1, 'úy': 1, 'vh': 1, 'fj': 1, 'zt': 1, 'mg': 1, 'gb': 1, 'uj': 1, 'ún': 1, 'gè': 1, 'iæ': 1, 'æp': 1, 'yj': 1, 'fê': 1, 'oö': 1, 'èl': 1, 'üd': 1, 'fá': 1, 'pd': 1}\n"
     ]
    }
   ],
   "source": [
    "with open('frequencies.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8f898d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "836"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "82c3dc18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.60833333333333"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "treshold = np.mean([198.5, 423.8, 331.8, 0, 0, 13.2]) / 2\n",
    "treshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cea3b631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processed_test_data(data: list, is_wrong_data: bool = False) -> dict:\n",
    "    processed = dict()\n",
    "\n",
    "    for idx, row in enumerate(data):\n",
    "        text_: str = row if is_wrong_data else processing_text(row, punctuation)\n",
    "        counts_: dict = get_frequency_ngram(text_, n_gram=2)\n",
    "\n",
    "        n_chars_in_row = len(text_.replace(' ', ''))\n",
    "        processed[idx] = (n_chars_in_row, counts_)\n",
    "    \n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c009f728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(n_chars: int, d: dict) -> float:\n",
    "    score = 1\n",
    "    \n",
    "    for k, v in d.items():\n",
    "        score *= data.get(k, 0) * v\n",
    "\n",
    "    return score ** (1. / n_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ca78b94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores(processed_dict: dict, input_list: list, treshold: float = treshold) -> None:\n",
    "    for k, v in processed_dict.items():\n",
    "        print(input_list[k])\n",
    "        \n",
    "        score = get_score(*v)\n",
    "        print(f'score={score}')\n",
    "        \n",
    "        type_ = 'clear' if score >= treshold else 'harmful'\n",
    "        print(f'sentence is {type_}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4719a366",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_correct = [\n",
    "    \"She had some amazing news to share but nobody to share it with.\",\n",
    "    \"Just because the water is red doesn't mean you can't drink it.\",\n",
    "    \"It's important to remember to be aware of rampaging grizzly bears.\"\n",
    "]\n",
    "\n",
    "test_wrong = [\n",
    "    'adfkvar itsjvjdkdfdjj ddjfjvnnrdkfkd dldlvmskdsk troeovs',\n",
    "    'gioooogn ajdjjdbj dakjkjrj kfsknsfkksfvnjgmd djd dfnjnj',\n",
    "    'oogobmgk ahdhfdhvb adhhfhdfbdhbdfbhdh dhfabhdh'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a7a14256",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_correct_processed: dict = get_processed_test_data(test_correct)\n",
    "test_wrong_processed: dict = get_processed_test_data(test_wrong, is_wrong_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "05215893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She had some amazing news to share but nobody to share it with.\n",
      "score=198.48024559928982\n",
      "sentence is clear\n",
      "\n",
      "Just because the water is red doesn't mean you can't drink it.\n",
      "score=423.84943825263986\n",
      "sentence is clear\n",
      "\n",
      "It's important to remember to be aware of rampaging grizzly bears.\n",
      "score=331.81778671008266\n",
      "sentence is clear\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_scores(test_correct_processed, test_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9d39e0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adfkvar itsjvjdkdfdjj ddjfjvnnrdkfkd dldlvmskdsk troeovs\n",
      "score=0.0\n",
      "sentence is harmful\n",
      "\n",
      "gioooogn ajdjjdbj dakjkjrj kfsknsfkksfvnjgmd djd dfnjnj\n",
      "score=0.0\n",
      "sentence is harmful\n",
      "\n",
      "oogobmgk ahdhfdhvb adhhfhdfbdhbdfbhdh dhfabhdh\n",
      "score=13.197323623660811\n",
      "sentence is harmful\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_scores(test_wrong_processed, test_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5391b873",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pattern-recog",
   "language": "python",
   "name": "pattern-recog"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
